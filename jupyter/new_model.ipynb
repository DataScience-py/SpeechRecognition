{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "импорт всех библиотек "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация модели\n",
    "Она будет похожа на DeepSpeech2.\n",
    "Плюсы:\n",
    " - логичность и простота\n",
    " - мало гиперпараметров (в зависимости от размера модели)\n",
    " - лучше чем обычная сеть из RNN (решена проблема взрывающихся градиентов)\n",
    "Минусы:\n",
    " - требует большого объема данных для обучения\n",
    " - зависит от ресурсов\n",
    "\n",
    "Архитектура:\n",
    "    - входной слой (входная матрица), размерность входная:, выходная размерность: \n",
    "    - CNN layers для уменьшения размера входной матрицы (решение взрывных градиентов), входная размерность:  ,размерность выходная\n",
    "    - RNN Layers обработка матрицы значения по времени: размерность входная: , размерность выходная:\n",
    "    - Fully connected layers для более точного предсказания ответа модели для каждого момента времени\n",
    "    - Softmax -> получение итого результата (из логитов в вероятность)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, dropout_rate=0.3):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels, out_channels, kernel_size, padding=kernel_size // 2\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv1d принимает (B, C, T), LayerNorm требует переставить размерности\n",
    "        x = self.conv(x)  # (B, C_out, T)\n",
    "        x = x.permute(0, 2, 1)  # (B, C_out, T) -> (B, T, C_out)\n",
    "        x = self.layer_norm(x)  # Нормализация\n",
    "        x = x.permute(0, 2, 1)  # (B, T, C_out) -> (B, C_out, T)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate=0.3):\n",
    "        super(GRUBlock, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.gru(x)  # (B, T, H_out)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем все под части в 1 модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASRModel(nn.Module):\n",
    "    def __init__(self, input_channels, gru_hidden_size, num_classes, dropout_rate=0.3):\n",
    "        super(ASRModel, self).__init__()\n",
    "\n",
    "        # Сверточные блоки\n",
    "        self.conv_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(input_channels, 32, dropout_rate=dropout_rate),\n",
    "                ConvBlock(32, 64, dropout_rate=dropout_rate),\n",
    "                ConvBlock(64, 128, dropout_rate=dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Рекуррентные блоки\n",
    "        self.gru_blocks = nn.ModuleList(\n",
    "            [\n",
    "                GRUBlock(128, gru_hidden_size, dropout_rate=dropout_rate)\n",
    "                for _ in range(7)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Полносвязные слои\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(gru_hidden_size, gru_hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(gru_hidden_size // 2, num_classes),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Сверточные блоки\n",
    "        for conv in self.conv_blocks:\n",
    "            x = conv(x)  # (B, C_out, T)\n",
    "\n",
    "        # Переставляем размерности для GRU\n",
    "        x = x.permute(0, 2, 1)  # (B, C_out, T) -> (B, T, C_out)\n",
    "\n",
    "        # Рекуррентные блоки\n",
    "        for gru in self.gru_blocks:\n",
    "            x = gru(x)  # (B, T, H_out)\n",
    "\n",
    "        # Полносвязные слои\n",
    "        x = x[:, -1, :]  # Берем последний временной шаг (B, H_out)\n",
    "        x = self.fc(x)  # Полносвязные слои\n",
    "        x = self.softmax(x)  # Преобразование в вероятности\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 4])\n",
      "[[2 3 4]\n",
      " [5 6 7]]\n",
      "абв\n",
      "['абв', 'где']\n"
     ]
    }
   ],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self, char_map: str | list | set, use_blank_token: bool = True):\n",
    "        if isinstance(char_map, list):\n",
    "            char_map = \"\".join(char_map)\n",
    "        if isinstance(char_map, set):\n",
    "            char_map = \"\".join(char_map)\n",
    "        self.char_map = char_map\n",
    "        self.use_blank_token = use_blank_token\n",
    "        self.char_to_int = self.__create_char_to_index()\n",
    "        self.int_to_char = self.__create_int_char()\n",
    "\n",
    "    def __create_int_char(self):\n",
    "        start_index = 0\n",
    "        if self.use_blank_token:\n",
    "            start_index = 1\n",
    "        index_to_char = {\n",
    "            idx: char for idx, char in enumerate(self.char_map, start=start_index)\n",
    "        }\n",
    "        return index_to_char\n",
    "\n",
    "    def __create_char_to_index(self):\n",
    "        start_index = 0\n",
    "        if self.use_blank_token:\n",
    "            start_index = 1\n",
    "        char_to_index = {\n",
    "            char: idx for idx, char in enumerate(self.char_map, start=start_index)\n",
    "        }\n",
    "        return char_to_index\n",
    "\n",
    "    def __convert_list_to_tensor(\n",
    "        self, data: list[list[int]], torch_device=\"cpu\"\n",
    "    ) -> torch.Tensor:\n",
    "        # Converts a batch of lists to a torch.Tensor\n",
    "        return torch.tensor(data, device=torch_device)\n",
    "\n",
    "    def __convert_list_to_numpy(self, data: list[list[int]]) -> np.ndarray:\n",
    "        # Converts a batch of lists to a numpy array\n",
    "        return np.array(data)\n",
    "\n",
    "    def encode(\n",
    "        self, text: str, types: str = \"list\", torch_device=\"cpu\"\n",
    "    ) -> list[int] | torch.Tensor | np.ndarray:\n",
    "        encoded = [self.char_to_int[char] for char in text]\n",
    "        if types == \"torch\":\n",
    "            return torch.tensor(encoded, device=torch_device)\n",
    "        elif types == \"numpy\":\n",
    "            return np.array(encoded)\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, indices: list[int] | torch.Tensor | np.ndarray) -> str:\n",
    "        if isinstance(indices, torch.Tensor):\n",
    "            indices = indices.tolist()\n",
    "        elif isinstance(indices, np.ndarray):\n",
    "            indices = indices.tolist()\n",
    "        return \"\".join([self.int_to_char.get([idx], \"\") for idx in indices])\n",
    "\n",
    "    def encode_batch(\n",
    "        self, texts: list[str], types: str = \"list\", torch_device=\"cpu\"\n",
    "    ) -> list[list[int]] | torch.Tensor | np.ndarray:\n",
    "        encoded_batch = [self.encode(text, types, torch_device) for text in texts]\n",
    "        if types == \"torch\":\n",
    "            return self.__convert_list_to_tensor(encoded_batch, torch_device)\n",
    "        elif types == \"numpy\":\n",
    "            return self.__convert_list_to_numpy(encoded_batch)\n",
    "        return encoded_batch\n",
    "\n",
    "    def decode_batch(\n",
    "        self, indices: list[list[int] | torch.Tensor | np.ndarray]\n",
    "    ) -> list[str]:\n",
    "        return [self.decode(idx) for idx in indices]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text_preprocessor = TextPreprocessor(\n",
    "    char_map=\" абвгдеёжзийклмнопрстуфхцчшщъыьэюя\", use_blank_token=True\n",
    ")\n",
    "\n",
    "encoded_text = text_preprocessor.encode(\"абв\", types=\"torch\")\n",
    "print(encoded_text)\n",
    "\n",
    "encoded_batch = text_preprocessor.encode_batch([\"абв\", \"где\"], types=\"numpy\")\n",
    "print(encoded_batch)\n",
    "\n",
    "decoded_text = text_preprocessor.decode(encoded_text)\n",
    "print(decoded_text)\n",
    "\n",
    "decoded_batch = text_preprocessor.decode_batch(encoded_batch)\n",
    "print(decoded_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128, n_fft=1024),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100),\n",
    ")\n",
    "\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128, n_fft=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_valid(data):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for waveform, utterance in data:\n",
    "        # Apply the MelSpectrogram transformation\n",
    "        spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        # Add to the list of spectrograms\n",
    "        spectrograms.append(spec)\n",
    "        # Convert the utterance to integers using the TextPreprocessor\n",
    "        label = text_preprocessor.encode(utterance.lower(), types=\"torch\")\n",
    "        labels.append(label)\n",
    "        # Input length is determined by the number of frames in the spectrogram\n",
    "        input_lengths.append(spec.shape[0] // 2)\n",
    "        # Label length is the length of the utterance\n",
    "        label_lengths.append(label.shape[0])\n",
    "\n",
    "    # Pad the spectrograms to the same length and remove the channel dimension\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).transpose(\n",
    "        1, 2\n",
    "    )\n",
    "    # Pad the labels\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths\n",
    "\n",
    "\n",
    "def data_processing_train(data):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for waveform, utterance in data:\n",
    "        # Apply the training transformations (MelSpectrogram, FrequencyMasking, TimeMasking)\n",
    "        spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        # Add to the list of spectrograms\n",
    "        spectrograms.append(spec)\n",
    "        # Convert the utterance to integers using the TextPreprocessor\n",
    "        label = text_preprocessor.encode(utterance.lower(), types=\"torch\")\n",
    "        labels.append(label)\n",
    "        # Input length is determined by the number of frames in the spectrogram\n",
    "        input_lengths.append(spec.shape[0] // 2)\n",
    "        # Label length is the length of the utterance\n",
    "        label_lengths.append(label.shape[0])\n",
    "\n",
    "    # Pad the spectrograms to the same length and remove the channel dimension\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).transpose(\n",
    "        1, 2\n",
    "    )\n",
    "    # Pad the labels\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GreedyDecoder(\n",
    "    output, labels, label_lengths, blank_label=0, collapse_repeated=True\n",
    "):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_preprocessor.decode(labels[i][: label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j - 1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_preprocessor.decode(decode))\n",
    "    return decodes, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalizes the text by removing all non-alphabetic characters and converting it to lowercase.\n",
    "    :param text: The text to be normalized.\n",
    "    :return: The normalized text.\n",
    "    \"\"\"\n",
    "    return \"\".join(\n",
    "        char for char in text.lower() if char in \" абвгдеёжзийклмнопрстуфхцчшщъыьэюя\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       path  \\\n",
      "0  public_youtube700/f/47/0b1f5586bbd7.opus   \n",
      "1  public_youtube700/8/c8/7367ee2bf1d7.opus   \n",
      "2  public_youtube700/1/1d/44616e05b60c.opus   \n",
      "3  public_youtube700/8/5d/a7e9f299fb9c.opus   \n",
      "4  public_youtube700/7/5b/b975fff943bf.opus   \n",
      "\n",
      "                                  sentence  \n",
      "0  public_youtube700/f/47/0b1f5586bbd7.txt  \n",
      "1  public_youtube700/8/c8/7367ee2bf1d7.txt  \n",
      "2  public_youtube700/1/1d/44616e05b60c.txt  \n",
      "3  public_youtube700/8/5d/a7e9f299fb9c.txt  \n",
      "4  public_youtube700/7/5b/b975fff943bf.txt  \n",
      "                                          path  \\\n",
      "0  public_youtube700_val/a/e3/0f2e35efe76d.wav   \n",
      "1  public_youtube700_val/f/0d/4cda8ca9e32c.wav   \n",
      "2  public_youtube700_val/c/44/643792385a6d.wav   \n",
      "3  public_youtube700_val/7/c6/3f876449790b.wav   \n",
      "4  public_youtube700_val/4/a8/cf00f3c177ac.wav   \n",
      "\n",
      "                                      sentence  \n",
      "0  public_youtube700_val/a/e3/0f2e35efe76d.txt  \n",
      "1  public_youtube700_val/f/0d/4cda8ca9e32c.txt  \n",
      "2  public_youtube700_val/c/44/643792385a6d.txt  \n",
      "3  public_youtube700_val/7/c6/3f876449790b.txt  \n",
      "4  public_youtube700_val/4/a8/cf00f3c177ac.txt  \n"
     ]
    }
   ],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data_path_csv: str, audio_path: str, sep=\",\"):\n",
    "        self.data_path_csv = data_path_csv\n",
    "        self.audio_path = audio_path\n",
    "        self.data = pd.read_csv(data_path_csv, sep=sep, header=None, usecols=[0, 1], names=[\"path\", \"sentence\"])\n",
    "        print(self.data.head())\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = os.path.join(self.audio_path, self.data.iloc[idx, 0])  # type: ignore str + str\n",
    "        sentence_path = os.path.join(\n",
    "            self.audio_path, self.data.iloc[idx, 1]\n",
    "        )\n",
    "        with open(sentence_path, \"r\") as file:\n",
    "            sentence = file.read()\n",
    "        sentence = normalization_text(sentence)\n",
    "        audio = torchaudio.load(path)[0]\n",
    "        return audio, sentence\n",
    "\n",
    "train_dataset = AudioDataset(data_path_csv=\"D:/Dataset/speech_ru/public_youtube700.csv\", audio_path=\"D:/Dataset/speech_ru\")\n",
    "valid_dataset = AudioDataset(data_path_csv=\"D:/Dataset/speech_ru/public_youtube700_val.csv\", audio_path=\"D:/Dataset/speech_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=data_processing_train)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=False, collate_fn=data_processing_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
